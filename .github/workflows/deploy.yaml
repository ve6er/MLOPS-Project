# .github/workflows/deploy.yaml

name: CD - Build and Deploy to EC2 via S3

on:
  workflow_run:
    workflows: ["MLOps CI/CD Pipeline"]
    types:
      - completed

jobs:
  build-and-deploy:
    if: github.event.workflow_run.conclusion == 'success'
    runs-on: ubuntu-latest
    
    env:
      IMAGE_NAME_AND_TAG: my-ml-api:latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11' # Use the same version as your ci-cd.yaml

      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          
      - name: Setup DVC
        uses: iterative/setup-dvc@v1

      - name: Pull artifacts from DVC
        run: |
          # This command pulls all data/models/artifacts from your S3 remote
          # Use the same remote name as in your ci-cd.yaml
          dvc pull -r mlops_remote --force
          
      - name: Build Docker image
        run: |
          docker build -t $IMAGE_NAME_AND_TAG .

      - name: Save Docker image to a tar file
        run: |
          docker save $IMAGE_NAME_AND_TAG -o image.tar

      - name: Upload image to S3
        run: |
          aws s3 cp image.tar s3://${{ secrets.AWS_S3_BUCKET }}/${{ secrets.S3_IMAGE_KEY }}
          echo "Image tarball uploaded to S3 bucket."

      - name: Deploy to EC2 via SSH
        uses: appleboy/ssh-action@v1.0.3
        with:
          host: ${{ secrets.EC2_HOST }}
          username: ${{ secrets.EC2_USERNAME }}
          key: ${{ secrets.EC2_SSH_KEY }}
          port: 22
          script: |
            # --- START: Add swap space to prevent OOM Kill ---
            if [ -f /swapfile ]; then
              echo "Swap file already exists."
            else
              echo "Creating 2GB swap file..."
              sudo fallocate -l 2G /swapfile
              sudo chmod 600 /swapfile
              sudo mkswap /swapfile
              sudo swapon /swapfile
              # Make swap permanent
              echo '/swapfile none swap sw 0 0' | sudo tee -a /etc/fstab
              echo "Swap file created and enabled."
            fi
            # --- END: Add swap space ---

            # Set variables
            S3_PATH="s3://${{ secrets.AWS_S3_BUCKET }}/${{ secrets.S3_IMAGE_KEY }}"
            LOCAL_IMAGE_FILE="/home/${{ secrets.EC2_USERNAME }}/image.tar"
            IMAGE_TAG_TO_RUN="${{ env.IMAGE_NAME_AND_TAG }}"
            
            echo "Downloading new image from $S3_PATH"
            aws s3 cp $S3_PATH $LOCAL_IMAGE_FILE --region ${{ secrets.AWS_REGION }}
            
            echo "Loading image into Docker"
            sudo docker load -i $LOCAL_IMAGE_FILE
            
            echo "Stopping and removing old container..."
            sudo docker stop ml-api-container || true
            sudo docker rm ml-api-container || true
            
            echo "Running new container..."
            # Using port 80 as you configured
            sudo docker run -d --name ml-api-container --restart always -p 80:5000 $IMAGE_TAG_TO_RUN
            
            echo "Cleaning up local tar file"
            rm $LOCAL_IMAGE_FILE
